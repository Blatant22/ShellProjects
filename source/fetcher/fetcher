#!/usr/bin/env bash
#cito M:755 O:0 G:0 T:/usr/bin/fetcher
#------------------------------------------------------------------------------
# Project Name      - Extra/source/fetcher/fetcher
# Started On        - Fri 18 Dec 01:42:22 GMT 2020
# Last Change       - Thu 13 Jan 20:03:13 GMT 2022
# Author E-Mail     - terminalforlife@yahoo.com
# Author GitHub     - https://github.com/terminalforlife
#------------------------------------------------------------------------------
# The point of Fetcher is to write something to replace and vastly improve on
# BDL (Batch Downloader), a very old Shell project I started years ago. I want
# it to be simple, lightweight, and much more pleasant to use, with more
# features than are found in BDL.
#
# Features:
#
#TODO: Add ability to download specific items and ranges from URL list.
#TODO: Add paging support via less(1) and more(1).
#TODO: Confirm URLs are valid.
#TODO: Consider handling long URLs when using 'list' or 'remove'.
#TODO: Automatically remove entries for links to files already downloaded.
#
#      This should be accompanied by a flag to disable this feature, if needed.
#
# Bugs:
#
# N/A
#
# Dependencies:
#
#   bash (>= 4.3-14)
#   coreutils (>= 8.28)
#   sed (>= 4.4-2)
#   wget (>= 1.19.4-1)
#------------------------------------------------------------------------------

CurVer='2022-01-13'
Progrm=${0##*/}

Usage() {
	while read; do
		printf '%s\n' "$REPLY"
	done <<-EOF
		Usage: $Progrm [OPTS] ACTION

		  -h, --help               - Display this help information.
		  -v, --version            - Output the version datestamp.
		  -C, --no-color           - Disable ANSI color escape sequences.

		  Below are a list of ACTIONs:

		  add URL                  - Add a URL to the list.
		  fetch                    - Download all of the stored URLs.
		  list                     - List all of the stored URLs.
		  remove                   - Remove a stored URL.
	EOF
}

Err() {
	printf 'Err: %s\n' "$2" 1>&2
	(( $1 > 0 )) && exit $1
}

MainDir="$HOME/.config/$Progrm"
LinkFile="$MainDir/links"

# The [p]retty names, for use in errors and such.
P_LinkFile="~/${LinkFile#/home/*/}"

while [[ -n $1 ]]; do
	case $1 in
		--help|-h|-\?)
			Usage; exit 0 ;;
		--version|-v)
			printf '%s\n' "$CurVer"; exit 0 ;;
		--no-color|-C)
			NoColor='True' ;;
		-*)
			Err 1 'Incorrect option(s) specified.' ;;
		*)
			break ;;
	esac
	shift
done

(( $# == 0 )) && Err 1 "Argument error -- see: $Progrm -h"

while [ -n "$1" ]; do
	case $1 in
		fetch|list|remove)
			Action=$1 ;;
		add)
			Action=$1

			if [[ -z $2 ]]; then
				Err 1 "Missing URL for ACTION '$1' -- nothing to $Action."
			else
				AddURL=$2
			fi

			shift ;;
		*)
			Err 1 "Chosen ACTION '$1' invalid." ;;
	esac
	shift
done

DepCount=0
for Dep in mkdir sed wget; do
	if ! type -P "$Dep" &> /dev/null; then
		Err 0 "Dependency '$Dep' not met."
		(( DepCount++ ))
	fi
done

(( DepCount > 0 )) && exit 1

[[ -d $MainDir ]] || mkdir -p "$MainDir"

# ANSI color escape sequences.
if [[ $NoColor != True ]]; then
	C_Red='\e[1;31m'
	C_Green='\e[1;32m'
	C_Reset='\e[0m'
fi

#----------------------------------------------------------------Main Functions

CheckIfEmpty() {
	Line=0
	while read; do
		[[ $REPLY == \#* || $REPLY == '' ]] && continue

		(( Line++ ))
	done < "$LinkFile"

	(( Line == 0 )) && Err 1 "No stored URLs found -- nothing to $1."
}

#---------------------------------------------------Create Link File If Missing

if ! [[ -f $LinkFile ]]; then
	InitLine="# URLs from which to download data using ${Progrm^} $CurVer."
	printf '%s\n\n' "$InitLine" > "$LinkFile"
elif ! [[ -r $LinkFile ]]; then
	Err 1 "File '$P_LinkFile' unreadable."
fi

#-----------------------------------------------------------------------Actions

if [[ $Action == list ]]; then
	CheckIfEmpty "$Action"

	printf 'URLs currently stored:\n\n'

	Line=0
	while read; do
		[[ $REPLY == \#* || $REPLY == '' ]] && continue

		(( Line++ ))
		printf "$C_Green%2d$C_Reset:  $C_Red%s$C_Reset\n" $Line "$REPLY"
	done < "$LinkFile"
	printf '\n'
elif [[ $Action == add ]]; then
	while read; do
		[[ $REPLY == \#* || $REPLY == '' ]] && continue

		# Avoid duplicates.
		if [[ $REPLY == $AddURL ]]; then
			Err 1 'URL already exists -- nothing to do.'
		fi
	done < "$LinkFile"
	printf '\n'

	printf '%s\n' "$AddURL" >> "$LinkFile"
elif [[ $Action == remove ]]; then
	CheckIfEmpty "$Action"

	printf 'URLs currently stored:\n\n'

	while read; do
		[[ $REPLY == \#* || $REPLY == '' ]] && continue

		(( Line++ ))
		URLs+=("$Line|$REPLY")
		printf "$C_Green%2d$C_Reset:  $C_Red%s$C_Reset\n" $Line "$REPLY"
	done < "$LinkFile"
	printf '\n'

	URL=2
	read -p 'Select a URL to remove: (1-20) ' URL
	case $URL in
		[1-9]|[1-9][0-9])
			for Link in "${URLs[@]}"; {
				if (( ${Link%%|*} == URL ]]; then
					ToRemove=${Link#*|}
					break
				fi
			}

			if [[ -n $ToRemove ]]; then
				sed -i "/${ToRemove//\//\\\/}/d" "$LinkFile"
			else
				Err 1 "Requested URL not found."
			fi ;;
		*|'')
			Err 1 'Invalid or missing URL number provided.' ;;
	esac
elif [[ $Action == fetch ]]; then
	CheckIfEmpty "$Action"

	while read; do
		[[ $REPLY == \#* || $REPLY == '' ]] && continue

		wget -qc --show-progress "$REPLY"
	done < "$LinkFile"
fi
