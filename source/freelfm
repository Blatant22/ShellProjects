#!/usr/bin/env bash
#cito M:755 O:0 G:0 T:/usr/bin/freelfm
#------------------------------------------------------------------------------
# Project Name      - Extra/source/freelfm
# Started On        - Fri 15 Sep 21:19:42 BST 2017
# Last Change       - Sat 13 May 03:03:02 BST 2023
# Author E-Mail     - terminalforlife@yahoo.com
# Author GitHub     - https://github.com/terminalforlife
#------------------------------------------------------------------------------
# Download last.fm's free music into the current working directory.
#
# 2023-05-12: Currently 12 pages holding 202+ MP3 tracks, with 25 being ignored
#             because of URL decoding issues due to some non-English text.
#
# Downloaded tracks will not clobber those partially-downloaded.
#
# Does not show you a total number of tracks available, because that would
# require unnecessarily parsing every single page, when the user might not want
# all of them. Therefore, not providing this output seems more respectiful to
# the server(s) hosting the tracks. As a result, FreeLFM is faster.
#
# Features:
#
#TODO: Add a target directory flag.
#
# Bugs:
#
#TODO: `printf` in `DecodeURL()` fails with some non-English characters.
#
# Dependencies:
#
#   coreutils (>= 8.25-2)
#   wget (>= 1.17.1-1)
#------------------------------------------------------------------------------

CurVer='2023-05-13'
Progrm=${0##*/}

Usage() {
	read -d '' <<-EOF
		Usage: $Progrm [OPTS] PAGE [PAGE ...]

		  -h, --help               - Displays this help information.
		  -v, --version            - Output only the version datestamp.
		  -a, --act {sd|ss}        - When done, either shut down or suspend.
		  -O, --links-only         - List download URLs instead of downloading.
	EOF

	printf '%s' "$REPLY"
}

Err() {
	printf 'Err: %s\n' "$2" 1>&2
	(( $1 > 0 )) && exit $1
}

LinksOnly=
PowerAct=
PageURL='https://www.last.fm/music/+free-music-downloads?page'

while [[ -n $1 ]]; do
	case $1 in
		--help|-h)
			Usage; exit 0 ;;
		--version|-v)
			printf '%s\n' "$CurVer"; exit 0 ;;
		--act|-a)
			case ${2,,} in
				ss|sd)
					PowerAct=$2 ;;
				'')
					Err 1 "Option '$1' requires an argument." ;;
				*)
					Err 1 "Option '$1' given invalid argument." ;;
			esac
			shift ;;
		-O|--links-only)
			LinksOnly='True' ;;
		-*)
			Err 1 'Incorrect argument(s) specified.' ;;
		*)
			break ;;
	esac
	shift
done

DepCount=0
for CurDep in wget sleep systemctl; {
	if ! type -P "$CurDep" &> /dev/null; then
		[[ $CurDep == systemctl && -z $PowerAct ]] && continue

		Err 0 "Dependency '$CurDep' not met."
		(( DepCount++ ))
	fi
}

(( DepCount > 0 )) && exit 1

#----------------------------------------------------------------Main Functions

# I know this can be done in a simple way using BASH's parameter expansion's
# pattern substitution, but this was a huge pain to figure out, and I'm quite
# proud of it, so it's here to stay. After testing, it turns out this method
# is ever so slightly faster, although it took 1000 iterations to even notice
# that negible amount.
#
# Usage: DecodeURL VARIABLE URL
DecodeURL() {
	declare -n Return=$1
	URL=$2

	OutChars=
	HexChars=
	HexFound=
	Len=${#URL}
	for (( Index = 0; Index < Len; Index++ )); {
		CurChar=${URL:Index:1}
		if [[ $HexFound == True ]]; then
			HexChars+=$CurChar
			HexTest="\x$HexChars"

			# Have to use `printf` here, due to limitations of shell. I could
			# use the $'...' syntax, but the shell won't allow a variable
			# where the elipsis is, and you weirdly must use single-quotes. The
			# only way I know around that is to use `eval`, unfortunately.
			#
			# Note that `printf` will spit out a null value if so-called not
			# valid. Hence using the character class to check it's actually
			# printable, vs. just checking the variable is not empty.
			#
			# If `printf` fails, the filename probably has weird Unicode, that
			# even with `\u` won't decode properly. Frustrating, but at that
			# point, just ignore the file to make life easier.
			if ! printf -v HexTest "\x$HexChars" 2> /dev/null; then
				return 1
			fi

			if [[ $HexTest == [[:print:]] ]]; then
				OutChars+=$HexTest
				HexFound=
				HexChars=
			fi
		elif [[ $CurChar == % ]]; then
			HexFound='True'
		elif [[ $CurChar == '+' ]]; then
			OutChars+=' '
		else
			OutChars+=$CurChar
		fi
	}

	Return=$OutChars
}

# Usage: SortInts {<|>} ARRAY
#
# Numerically sorts ascending or descending depending on `$1`, and filters out
# duplicate integers from the array.
SortInts() {
	declare -n Arr=$2

	Len=${#Arr[@]}
	for (( Iter = 0; Iter <= Len; Iter++ )); {
		Switched='False'
		for (( Index = 0; Index < Len - (1 + Iter); Index++ )); {
			if (( ${Arr[Index]} == ${Arr[Index + 1]} )); then
				Arr=("${Arr[@]:0:Index}" "${Arr[@]:Index + 1:Len - 1}")
				Len=${#Arr[@]}

				# We don't want to break yet.
				continue
			elif (( ${Arr[Index]} $1 ${Arr[Index + 1]} )); then
				Temp=${Arr[Index]}
				Arr[Index]=${Arr[Index + 1]}
				Arr[Index + 1]=$Temp

				Switched='True'
			fi
		}

		[[ $Switched == False ]] && break
	}
}

# Usage: Title VARIABLE STRING
#
# Not an especially hard and fast rule, but it does keep it more in line with
# a standard UK title in which small prepositions and conjunctions are not
# capitalised, but everything else is. I'd be more specific, but it'd get silly
# after a while.
#
# The reason for this is because whoever manages the site is inconsistent with
# their titles, with different styles and some not even being titles at all. To
# save people's sanity, for those like me that care, I've handled it.
Title() {
	declare -n Title=$1

	read -a Fields <<< "$2"

	Out=
	Len=${#Fields[@]}
	for (( Index = 0; Index < Len; Index++ )); {
		Field=${Fields[Index]}
		case $Field in
			the|or|of|in|for|to|on|and|with)
				if (( Index == 0 )); then
					Out+="${Field^}"
				else
					Out+="$Field"
				fi ;;
			*)
				Out+="${Field^}" ;;
		esac

		(( Index != Len - 1 )) && Out+=' '
	}

	Title=$Out
}

Info() {
	[[ $LinksOnly == True ]] || printf '%s\n' "$1"
}

#----------------------------------------------------Determine Valid Page Range

# Kinder to the servers if page 1 is later requested.
Page1Data=`wget -qO - "$PageURL=1"`

PagesFound=()
while read; do
	if [[ $REPLY == *'<a href="?page='+([[:digit:]])'">'* ]]; then
		for Digits in ${REPLY//[^[:digit:]]/ }; {
			FoundDupe=
			for Page in "${PagesFound[@]}"; {
				if [[ $Page == $Digits ]]; then
					FoundDupe='True'

					break
				fi
			}

			[[ $FoundDupe == True ]] || PagesFound+=($Digits)
		}
	fi
done <<< "$Page1Data"

# Ensure we know the maximum page by sorting.
SortInts '<' PagesFound

PageMax=${PagesFound[0]}

Info "Found $PageMax available page(s)."

#-------------------------Validate Target Pages, Handle Ranges, and Sort Result

TargetPages=()
while [[ -n $1 ]]; do
	if [[ $1 == +([[:digit:]])-+([[:digit:]]) ]]; then
		Left=${1%-*}
		Right=${1#*-}

		if (( Left >= Right )); then
			Err 0 "Page range '$1' invalid."
			(( PageErrs++ ))

			shift
			continue
		fi

		PushArgs=()
		for (( Nr = Left; Nr <= Right; Nr++ )); {
			PushArgs+=($Nr)
		}

		shift

		set -- $* "${PushArgs[@]}"

		# We don't want to `shift` twice, and the below checks will be
		# performed on the new arguments which were added above.
		continue
	fi

	if [[ $1 != +([[:digit:]]) ]]; then
		Err 0 "Page number(s) '$1' invalid."
		(( PageErrs++ ))
	elif ! (( $1 >= 1 && $1 <= PageMax )); then
		Err 0 "Page number '$1' not found."
		(( PageErrs++ ))
	else
		TargetPages+=("$1")
	fi

	shift
done

(( PageErrs > 0 )) && exit 1

if (( ${#TargetPages[@]} == 0 )); then
	Err 1 "Page number(s) required -- see: $Progrm -h"
fi

# Sort ascending so we handle pages in order.
SortInts '>' TargetPages

#------------------------------------------------------Fetch List of Track URLs

TrackURLs=()
TotalTracksAll=0
for PageNr in "${TargetPages[@]}"; {
	if (( PageNr == 1 )); then
		PageData=$Page1Data
	else
		PageData=`wget -qO - "$PageURL=$PageNr"`
	fi

	# Grab direct download link for each track.
	TotalTracksPage=0
	while read; do
		if [[ $REPLY == *\"https:*.mp3\"* ]]; then
			FileURL=${REPLY#*https://}
			FileURL=${FileURL%.mp3*}
			FileURL="https://$FileURL.mp3"
			TrackURLs+=("$FileURL")

			(( TotalTracksAll++ ))
			(( TotalTracksPage++ ))
		fi
	done <<< "$PageData"

	Info "Found $TotalTracksPage track(s) on page $PageNr."
}

#-------------------------------------------Begin Downloading or Listing Tracks

SuccessDL=0
DecodeFails=0
if [[ $LinksOnly == True ]]; then
	printf '%s\n' "${TrackURLs[@]}"
else
	for TrackURL in "${TrackURLs[@]}"; {
		TrackName=${TrackURL##*/}

		# Cleanse the filename for our local version. Skipping undecodable
		# filenames, at least until a sane solution can be found to include
		# them. Refer to `DecodeURL()` for more information.
		if ! DecodeURL TrackName "$TrackName"; then
			(( DecodeFails++ ))

			continue
		fi

		Title TrackName "$TrackName"

		Info "Found: ${TrackName%.mp3}"
		if wget -qc -O ./"$TrackName" "$TrackURL"; then
			(( SuccessDL++ ))
		else
			Info 'Error(s) detected.'
		fi
	}
fi

Info "Finished! Downloaded $SuccessDL/$TotalTracksAll track(s)."

#-------------------------------------------------Power Down or Suspend Machine

if [[ -n $PowerAct ]]; then
	read -d '' <<-EOF
		WARNING: System shutdown in 30 seconds!
		         Press Ctrl + C to cancel, ...
	EOF

	printf '%s' "$REPLY"

	sleep 30s || exit 0
	case $PowerAct in
		sd) systemctl shutdown ;;
		ss) systemctl suspend ;;
	esac
fi
