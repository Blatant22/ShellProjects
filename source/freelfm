#!/usr/bin/env bash
#cito M:755 O:0 G:0 T:/usr/bin/freelfm
#------------------------------------------------------------------------------
# Project Name      - Extra/source/freelfm
# Started On        - Fri 15 Sep 21:19:42 BST 2017
# Last Change       - Fri 12 May 04:20:20 BST 2023
# Author E-Mail     - terminalforlife@yahoo.com
# Author GitHub     - https://github.com/terminalforlife
#------------------------------------------------------------------------------
# Download last.fm's free music into the current working directory.
#
# The current max page is 12. The total number is 220+ MP3 tracks. Except the
# tracks themselves, the files are saved in '/tmp'.
#
# Features:
#
#TODO: Finish final `$PowerAct` section.
#TODO: Consider a more helpful description and flag usage for acting.
#TODO: Getting max page, but not telling user what the valid range is.
#TODO: Add support for cURL, with it taking precedence.
#
# Bugs:
#
#TODO: Page 1 is downloaded twice. Store page 1 in variable if it's requested.
#TODO: Multiple duplicate pages can be provided by the user -- handle this.
#
# Dependencies:
#
#   coreutils (>= 8.25-2)
#   wget (>= 1.17.1-1)
#------------------------------------------------------------------------------

CurVer='2023-05-12'
Progrm=${0##*/}

Usage() {
	read -d '' <<-EOF
		Usage: $Progrm [OPTS] PAGE [PAGE ...]

		  -h, --help               - Displays this help information.
		  -v, --version            - Output only the version datestamp.
		  -a, --act {sd|ss}        - When done, either shut down or suspend.
		  -O, --links-only         - List download URLs instead of downloading.
	EOF

	printf '%s' "$REPLY"
}

Err() {
	printf 'Err: %s\n' "$2" 1>&2
	(( $1 > 0 )) && exit $1
}

LinksOnly=
PowerAct=
PageURL='https://www.last.fm/music/+free-music-downloads?page'

while [[ -n $1 ]]; do
	case $1 in
		--help|-h)
			Usage; exit 0 ;;
		--version|-v)
			printf '%s\n' "$CurVer"; exit 0 ;;
		--act|-a)
			case ${2,,} in
				ss|sd)
					PowerAct=$2 ;;
				'')
					Err 1 "Option '$1' requires an argument." ;;
				*)
					Err 1 "Option '$1' given invalid argument." ;;
			esac
			shift ;;
		-O|--links-only)
			LinksOnly='True' ;;
		-*)
			Err 1 'Incorrect argument(s) specified.' ;;
		*)
			break ;;
	esac
	shift
done

DepCount=0
for CurDep in mkdir mktemp wget; {
	if ! type -P "$CurDep" &> /dev/null; then
		Err 0 "Dependency '$CurDep' not met."
		(( DepCount++ ))
	fi
}

(( DepCount > 0 )) && exit 1

(( $# == 0 )) && Err 1 "Page number(s) required -- see: $Progrm -h"

#----------------------------------------------------------------Main Functions

SigHandler() {
	Sig=$?

	rm -r "$TempDir"

	exit $Sig
}

# I know this can be done in a simple way using BASH's parameter expansion's
# pattern substitution, but this was a huge pain to figure out, and I'm quite
# proud of it, so it's here to stay. After testing, it turns out this method
# is ever so slightly faster, although it took 1000 iterations to even notice
# that negible amount.
#
# It was mainly a pain because there was an annoying gotcha with seemingly
# empty characters returned by `printf`, but in-fact they simply wern't
# printable, hence the POSIX character class.
#
# To avoid using command substitution when using this function, it would be
# best to make use of a name reference via `declare`. I'll get around to that
# eventually.
DecodeURL() {
	URL=$1

	OutChars=
	HexChars=
	HexFound=
	Len=${#URL}
	for (( Index = 0; Index < Len; Index++ )); {
		CurChar=${URL:Index:1}
		if [[ $HexFound == True ]]; then
			HexChars+=$CurChar
			printf -v HexTest "\x$HexChars"
			if [[ $HexTest == [[:print:]] ]]; then
				OutChars+=$HexTest
				HexFound=
				HexChars=
			fi
		elif [[ $CurChar == % ]]; then
			HexFound='True'
		else
			OutChars+=$CurChar
		fi
	}

	printf '%s\n' "$OutChars"
}

#----------------------------------------------------Determine Valid Page Range

PagesFound=(1)
while read; do
	if [[ $REPLY == *'<a href="?page='+([[:digit:]])'">'* ]]; then
		for Digits in ${REPLY//[^[:digit:]]/ }; {
			FoundDupe=
			for Page in "${PagesFound[@]}"; {
				if [[ $Page == $Digits ]]; then
					FoundDupe='True'

					break
				fi
			}

			[[ $FoundDupe == True ]] || PagesFound+=($Digits)
		}
	fi
done <<< "$(wget -qO - "$PageURL=1")"

# Ensure we know the maximum page by sorting.
Len=${#PagesFound[@]}
for (( Iter = 0; Iter <= Len; Iter++ )); {
	Switched='False'
	for (( Index = 0; Index < Len - (1 + Iter); Index++ )); {
		if (( ${PagesFound[Index]} < ${PagesFound[Index + 1]} )); then
			Temp=${PagesFound[Index]}
			PagesFound[Index]=${PagesFound[Index + 1]}
			PagesFound[Index + 1]=$Temp

			Switched='True'
		fi
	}

	[[ $Switched == False ]] && break
}

PageMax=${PagesFound[0]}

#----------------------------------Fetch List of Track URLs Per the Valid Pages

TempDir=`mktemp -d`

trap SigHandler EXIT INT

for PageNr; {
	if [[ $PageNr != +([0-9]) ]]; then
		Err 0 "Page number '$PageNr' invalid."
		continue
	elif ! (( PageNr >= 1 && PageNr <= PageMax )); then
		Err 0 "Page number '$PageNr' not found."
		continue
	fi

	CurPageURL="$PageURL=$PageNr"

	# Grab direct download link for each track.
	TrackURLs=()
	while read; do
		if [[ $REPLY == *\"https:*.mp3\"* ]]; then
			FileURL=${REPLY#*https://}
			FileURL=${FileURL%.mp3*}
			FileURL="https://$FileURL.mp3"
			TrackURLs+=("$FileURL")
		fi
	done <<< "$(wget -qO - "$CurPageURL")"
}

#-------------------------------------------Begin Downloading or Listing Tracks

if [[ $LinksOnly == True ]]; then
	printf '%s\n' "${TrackURLs[@]}"
else
	for TrackURL in "${TrackURLs[@]}"; {
		TrackName=${TrackURL##*/}
		TrackName=${TrackName%.mp3}

		# Cleanse the filename for our local version.
		TrackName=${TrackName//+/ }
		TrackName=`DecodeURL "$TrackName"`

		wget -qc --show-progress -O ./"$TrackName".mp3 "$TrackURL"
	}
fi

#---------------------------------------------------------------------Finish Up

if [[ -n $PowerAct ]]; then
	:
fi
